{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b75fa3a",
   "metadata": {},
   "source": [
    "# Pytorch를 활용한 hand sign 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bfdbeee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "from tqdm import tqdm as tqdmd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db042147",
   "metadata": {},
   "source": [
    "## Dataset Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeeddd5",
   "metadata": {},
   "source": [
    "![ASL](./image/01.png)\n",
    "* ASL(American Sign Language) alphabet은 총 26개가 있지만 dataset에서는 25개 밖에 없다. \n",
    "* 그 이유는 Z가 검지로 Z를 그리는 것이기 때문에 사진으로는 표현이 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187e677",
   "metadata": {},
   "source": [
    "## Image dir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30b50388",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"Train/\"\n",
    "TEST_DIR = \"Test/\"\n",
    "TRAIN_DIR_LIST = os.listdir(TRAIN_DIR)\n",
    "TEST_DIR_LIST = os.listdir(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0fa8337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trian Dataset\n",
    "df = pd.DataFrame(columns = ['label', 'dir'])\n",
    "for i in TRAIN_DIR_LIST:\n",
    "    for j in os.listdir(TRAIN_DIR + i +\"/\"):\n",
    "        data = {'label' : i, 'dir' : TRAIN_DIR + i + \"/\" + j }\n",
    "        df = df.append(data, ignore_index=True)\n",
    "df.to_csv(\"Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d357f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['label', 'dir'])\n",
    "for i in TEST_DIR_LIST:\n",
    "    for j in os.listdir(TEST_DIR + i +\"/\"):\n",
    "        data = {'label' : i, 'dir' : TEST_DIR + i + \"/\" + j }\n",
    "        df = df.append(data, ignore_index=True)\n",
    "df.to_csv(\"Test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a7e56ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7172 entries, 0 to 7171\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   7172 non-null   object\n",
      " 1   dir     7172 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 112.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6bf7f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"Train/train.csv\", index_col = 0)\n",
    "test_dataset = pd.read_csv(\"Test/test.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3aeb729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10014_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10021_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10023_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10050_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10056_A.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                  dir\n",
       "0     A  Train/A/10014_A.jpg\n",
       "1     A  Train/A/10021_A.jpg\n",
       "2     A  Train/A/10023_A.jpg\n",
       "3     A  Train/A/10050_A.jpg\n",
       "4     A  Train/A/10056_A.jpg"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a8f0bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    1294\n",
       "Q    1279\n",
       "L    1241\n",
       "W    1225\n",
       "F    1204\n",
       "S    1199\n",
       "D    1196\n",
       "O    1196\n",
       "T    1186\n",
       "X    1164\n",
       "I    1162\n",
       "U    1161\n",
       "N    1151\n",
       "C    1144\n",
       "A    1126\n",
       "Y    1118\n",
       "K    1114\n",
       "G    1090\n",
       "P    1088\n",
       "V    1082\n",
       "M    1055\n",
       "H    1013\n",
       "B    1010\n",
       "E     957\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831be68",
   "metadata": {},
   "source": [
    "## Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6565178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A\n",
       "1        A\n",
       "2        A\n",
       "3        A\n",
       "4        A\n",
       "        ..\n",
       "27450    Y\n",
       "27451    Y\n",
       "27452    Y\n",
       "27453    Y\n",
       "27454    Y\n",
       "Name: label, Length: 27455, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "02cda3d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-116-f6bf5d23faac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-116-f6bf5d23faac>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    train_dataset.loc[,][0]\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_dataset.loc[,][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "702e921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(train_dataset.loc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43cd3a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b904ca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACsklEQVR4nCXOy4ocVRgA4P//z3/q0vceeqZHjWMSh6CRZCMJgYC4EBcudKUvID6DK0F8jeyD4EYkixhEJSCixEkCgWScpOmYmcxUd09fqqqr6tS5ucj3BB/eQUQAD+jDPF4HlkCxA5mRQM0CADyAd85yLBz4POrMfN2UqY5JEAIAIMQC12XuZKOaYfzCpY0+MgAAIgIFHpCmo/Ls6X+bZ/ZbA+eRPCARkYg0GIDi4U93kqc/P3b3z1QTYngV8pD2jkbLQdS5t9F9vDr7/dVuuyQSQpC3+vDBcrp3a771HuNGL2nIHyZ9IkGC0Fvz5LenOABSaU+acC+5/uyPJ20CXWtJq3W/nzQ3dvfbWRVU1VEdX7w9KEiGEo3KTxqvzYtjlUN/ejcfd85h8rYgMkSMiMtyuwgpWE3N819+P7rSbBxfE5INA2rtlrP60U57Pl6kMOx++MnzY30FBEuuRZXpTCUHd3ez9bT12XkrA/fv9lunwIw+FNgf/D2nf6ZJ+PpHH6zo8P723ueBBQZjWIj+GxdWO5PNS8OLUZQ0zXg/u2bYMWvtVNERWwu//f7uuhXmYnQ4u/fFBRsp1thexagld+vhZshosoWav3jnK+U9E6CXsk4Zo1ZTApBN1Gxkvoucc46BnBCwasVdbEunzXg5PXn59Y4FBGAbGxv2TmzLaLIq00fFyz+//Dh17L1nL1D74UJ5W/mcT7M0+evqp76dAgIwGUTTCbOyKE2Gk9Pk191vEC1b8J5lSXHNQAoDqtVsetD5dmjSWAsPwDKP41Jppsh5rPJsdPOyKlsust4D3xA9vx68CVsZ13mejy/B4ckmVQEACR4rru27w96CqF7OU3XwI827xjWlB2QhA+HiMPCE5WyyLM7la12XFDprNEvZxjrUKZIrs7xU57sNhoKU0br6H3JTeI5v3PZ8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x1C3B4BA3430>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924039c3",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "* A ~ Y -> 0 ~ 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6906814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for i in range(25):\n",
    "    mapping[chr(65+i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4aff9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.replace(mapping)\n",
    "test_dataset = test_dataset.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "305e9f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    1294\n",
       "16    1279\n",
       "11    1241\n",
       "22    1225\n",
       "5     1204\n",
       "18    1199\n",
       "14    1196\n",
       "3     1196\n",
       "19    1186\n",
       "23    1164\n",
       "8     1162\n",
       "20    1161\n",
       "13    1151\n",
       "2     1144\n",
       "0     1126\n",
       "24    1118\n",
       "10    1114\n",
       "6     1090\n",
       "15    1088\n",
       "21    1082\n",
       "12    1055\n",
       "7     1013\n",
       "1     1010\n",
       "4      957\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0afac",
   "metadata": {},
   "source": [
    "## transformer\n",
    "* RandomHorizontalFlip(p)\n",
    "\n",
    "\n",
    "Horizontally flip the given image randomly with a given probability.\n",
    "* RandomRotation(degrees)\n",
    "\n",
    "\n",
    "Rotate the image by angle.\n",
    "* RandomVerticalFlip(p)\n",
    "\n",
    "\n",
    "Vertically flip the given image randomly with a given probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38bb3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = (28, 28)\n",
    "NUM_CLASSES = 25\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1313513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(value = 'val'):\n",
    "    if value == 'train':\n",
    "            transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(DIM),\n",
    "            transforms.RandomHorizontalFlip(p = 0.5),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomVerticalFlip(p = 0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(MEAN, STD)\n",
    "        ])\n",
    "            return transform\n",
    "    \n",
    "    elif value == 'val':\n",
    "            transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToPILImage(),\n",
    "            torchvision.transforms.Resize(DIM),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(MEAN, STD)\n",
    "        ])\n",
    "            return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb5756",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c661f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.labels = dataset.iloc[:, 0]\n",
    "        self.file_dir = dataset.iloc[:, 1]\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(os.path.join(self.file_dir[idx]))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype = torch.long)\n",
    "        # image, label을 return\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47191b68",
   "metadata": {},
   "source": [
    "## Check DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a0d52da",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-4f66739e6019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-145-adffea6b070f>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]"
     ]
    }
   ],
   "source": [
    "dataset = ASLDataset(dataset = train_dataset, transform = transform_data(\"train\"))\n",
    "dataLoader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dataiter = iter(dataLoader)\n",
    "feature, target = dataiter.next()\n",
    "print(feature)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa4124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
