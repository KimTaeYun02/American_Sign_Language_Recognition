{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b75fa3a",
   "metadata": {},
   "source": [
    "# Pytorch를 활용한 hand sign 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdbeee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "from tqdm import tqdm as tqdmd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db042147",
   "metadata": {},
   "source": [
    "## Dataset Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeeddd5",
   "metadata": {},
   "source": [
    "![ASL](./image/01.png)\n",
    "* ASL(American Sign Language) alphabet은 총 26개가 있지만 dataset에서는 25개 밖에 없다. \n",
    "* 그 이유는 Z가 검지로 Z를 그리는 것이기 때문에 사진으로는 표현이 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145e0fe",
   "metadata": {},
   "source": [
    "## Image dir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30b50388",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"Train/\"\n",
    "TEST_DIR = \"Test/\"\n",
    "TRAIN_DIR_LIST = os.listdir(TRAIN_DIR)\n",
    "TEST_DIR_LIST = os.listdir(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ce7070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trian Dataset\n",
    "df = pd.DataFrame(columns = ['label', 'dir'])\n",
    "for i in TRAIN_DIR_LIST:\n",
    "    for j in os.listdir(TRAIN_DIR + i +\"/\"):\n",
    "        data = {'label' : i, 'dir' : TRAIN_DIR + i + \"/\" + j }\n",
    "        df = df.append(data, ignore_index=True)\n",
    "df.to_csv(\"Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a454da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['label', 'dir'])\n",
    "for i in TEST_DIR_LIST:\n",
    "    for j in os.listdir(TEST_DIR + i +\"/\"):\n",
    "        data = {'label' : i, 'dir' : TEST_DIR + i + \"/\" + j }\n",
    "        df = df.append(data, ignore_index=True)\n",
    "df.to_csv(\"Test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a78d332d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7172 entries, 0 to 7171\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   7172 non-null   object\n",
      " 1   dir     7172 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 112.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc377a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"Train/train.csv\", index_col = 0)\n",
    "test_dataset = pd.read_csv(\"Test/test.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bfb66f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10014_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10021_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10023_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10050_A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Train/A/10056_A.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                  dir\n",
       "0     A  Train/A/10014_A.jpg\n",
       "1     A  Train/A/10021_A.jpg\n",
       "2     A  Train/A/10023_A.jpg\n",
       "3     A  Train/A/10050_A.jpg\n",
       "4     A  Train/A/10056_A.jpg"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755bf3e",
   "metadata": {},
   "source": [
    "## Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5b36869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a776491",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(train_dataset.loc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a62a8df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "593afe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACsklEQVR4nCXOy4ocVRgA4P//z3/q0vceeqZHjWMSh6CRZCMJgYC4EBcudKUvID6DK0F8jeyD4EYkixhEJSCixEkCgWScpOmYmcxUd09fqqqr6tS5ucj3BB/eQUQAD+jDPF4HlkCxA5mRQM0CADyAd85yLBz4POrMfN2UqY5JEAIAIMQC12XuZKOaYfzCpY0+MgAAIgIFHpCmo/Ls6X+bZ/ZbA+eRPCARkYg0GIDi4U93kqc/P3b3z1QTYngV8pD2jkbLQdS5t9F9vDr7/dVuuyQSQpC3+vDBcrp3a771HuNGL2nIHyZ9IkGC0Fvz5LenOABSaU+acC+5/uyPJ20CXWtJq3W/nzQ3dvfbWRVU1VEdX7w9KEiGEo3KTxqvzYtjlUN/ejcfd85h8rYgMkSMiMtyuwgpWE3N819+P7rSbBxfE5INA2rtlrP60U57Pl6kMOx++MnzY30FBEuuRZXpTCUHd3ez9bT12XkrA/fv9lunwIw+FNgf/D2nf6ZJ+PpHH6zo8P723ueBBQZjWIj+GxdWO5PNS8OLUZQ0zXg/u2bYMWvtVNERWwu//f7uuhXmYnQ4u/fFBRsp1thexagld+vhZshosoWav3jnK+U9E6CXsk4Zo1ZTApBN1Gxkvoucc46BnBCwasVdbEunzXg5PXn59Y4FBGAbGxv2TmzLaLIq00fFyz+//Dh17L1nL1D74UJ5W/mcT7M0+evqp76dAgIwGUTTCbOyKE2Gk9Pk191vEC1b8J5lSXHNQAoDqtVsetD5dmjSWAsPwDKP41Jppsh5rPJsdPOyKlsust4D3xA9vx68CVsZ13mejy/B4ckmVQEACR4rru27w96CqF7OU3XwI827xjWlB2QhA+HiMPCE5WyyLM7la12XFDprNEvZxjrUKZIrs7xU57sNhoKU0br6H3JTeI5v3PZ8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28 at 0x1C3B4BA3430>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5592e",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "* A ~ Y -> 0 ~ 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4f3754d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for i in range(25):\n",
    "    mapping[chr(65+i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b90d87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.replace(mapping)\n",
    "test_dataset = test_dataset.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "efd1fc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  dir                \n",
       "0      Train/A/10014_A.jpg    1\n",
       "17     Train/R/15735_R.jpg    1\n",
       "       Train/R/15677_R.jpg    1\n",
       "       Train/R/15674_R.jpg    1\n",
       "       Train/R/15670_R.jpg    1\n",
       "                             ..\n",
       "8      Train/I/18798_I.jpg    1\n",
       "       Train/I/18759_I.jpg    1\n",
       "       Train/I/18745_I.jpg    1\n",
       "       Train/I/1873_I.jpg     1\n",
       "24     Train/Y/9997_Y.jpg     1\n",
       "Length: 27455, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dcc7e",
   "metadata": {},
   "source": [
    "## transformer\n",
    "* RandomHorizontalFlip(p)\n",
    "\n",
    "\n",
    "Horizontally flip the given image randomly with a given probability.\n",
    "* RandomRotation(degrees)\n",
    "\n",
    "\n",
    "Rotate the image by angle.\n",
    "* RandomVerticalFlip(p)\n",
    "\n",
    "\n",
    "Vertically flip the given image randomly with a given probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f34696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = (28, 28)\n",
    "NUM_CLASSES = 25\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a3101dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(value = 'val'):\n",
    "    if value == 'train':\n",
    "            transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(DIM),\n",
    "            transforms.RandomHorizontalFlip(p = 0.5),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomVerticalFlip(p = 0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(MEAN, STD)\n",
    "        ])\n",
    "            return transform\n",
    "    \n",
    "    elif value == 'val':\n",
    "            transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToPILImage(),\n",
    "            torchvision.transforms.Resize(DIM),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(MEAN, STD)\n",
    "        ])\n",
    "            return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454e101",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d42994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_ids, labels, folder_dir = 'tran_images/', \n",
    "                 transform=None):\n",
    "        self.img_ids = img_ids\n",
    "        self.labels = labels\n",
    "        self.folder_dir = folder_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 read 및 label 저장\n",
    "        # cat\n",
    "        img = read_image(os.path.join(self.folder_dir+self.img_ids[idx]))\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype = torch.long)\n",
    "        # image, label을 return\n",
    "        return img, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
